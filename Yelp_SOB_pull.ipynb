{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b576363-c2f1-4e18-91f7-79d4e2ebea51",
   "metadata": {},
   "source": [
    "### Yelp API Pull Code for Terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d815f0f2-5bb5-435b-a636-d4e9f5c96073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#list of cities:\n",
    "#ADD TX cities that we did in initial pull \n",
    "# (Austin, TX, Dallas, TX, Fort Worth, TX, Houston, TX, San Antonio, TX, Laredo, TX)\n",
    "data_list=[\n",
    " 'Washington,DC',\n",
    " 'Boston,MA',\n",
    " 'Detroit,MI',\n",
    " 'Seattle,WA',\n",
    " 'Minneapolis,MN',\n",
    " 'Denver,CO',\n",
    " 'St.Louis,MO',\n",
    " 'Portland,OR',\n",
    " 'Cincinnati,OH',\n",
    " 'KansasCity,MO',\n",
    " 'Cleveland,OH',\n",
    " 'Columbus,OH',\n",
    " 'VirginiaBeach,VA',\n",
    " 'Charlotte,NC',\n",
    " 'Milwaukee,WI',\n",
    " 'Providence,RI',\n",
    " 'Nashville,TN',\n",
    " 'SaltLakeCity,UT',\n",
    " 'Raleigh,NC',\n",
    " 'Richmond,VA',\n",
    " 'Memphis,TN',\n",
    " 'OklahomaCity,OK',\n",
    " 'Hartford,CT',\n",
    " 'Louisville,KY',\n",
    " 'Bridgeport,CT',\n",
    " 'McAllen,TX',\n",
    " 'Tulsa,OK',\n",
    " 'Charleston,SC',\n",
    " 'Dayton,OH',\n",
    " 'ColoradoSprings,CO',\n",
    " 'Ogden,UT',\n",
    " 'Provo,UT',\n",
    " 'Knoxville,TN',\n",
    " 'GrandRapids,MI',\n",
    " 'Columbia,SC',\n",
    " 'NewHaven,CT',\n",
    " 'DesMoines,IA',\n",
    " 'Akron,OH',\n",
    " 'Toledo,OH',\n",
    " 'Worcester,MA',\n",
    " 'LittleRock,AR',\n",
    " 'Reno,NV',\n",
    " 'Spokane,WA',\n",
    " 'Madison,WI',\n",
    " 'Boise,ID',\n",
    " 'Denton,TX',\n",
    " 'Springfield,MA',\n",
    " 'Winston-Salem,NC',\n",
    " 'Chattanooga,TN',\n",
    " 'Greenville,SC',\n",
    " 'Durham,NC',\n",
    " 'Fayetteville,AR',\n",
    " 'Arlington,TX',\n",
    " 'Aurora,CO',\n",
    " 'Greensboro,NC',\n",
    " 'CorpusChristi,TX',\n",
    " 'FortCollins,CO',\n",
    " 'MyrtleBeach,SC',\n",
    " 'Fayetteville,NC',\n",
    " 'Lansing,MI',\n",
    " 'Lexington,KY',\n",
    " 'Youngstown,OH',\n",
    " 'Henderson,NV',\n",
    " 'AnnArbor,MI',\n",
    " 'St.Paul,MN',\n",
    " 'Canton,OH',\n",
    " 'Asheville,NC',\n",
    " 'Flint,MI',\n",
    " 'Concord,NC',\n",
    " 'Springfield,MO',\n",
    " 'Plano,TX',\n",
    " 'Davenport,IA',\n",
    " 'Lubbock,TX',\n",
    " 'Eugene,OR',\n",
    " 'Wilmington,NC',\n",
    " 'Salem,OR',\n",
    " 'Killeen,TX',\n",
    " 'NorthLasVegas,NV',\n",
    " 'Kennewick,WA',\n",
    " 'Irving,TX',\n",
    " 'Chesapeake,VA',\n",
    " 'Nashua,NH',\n",
    " 'Garland,TX',\n",
    " 'Norfolk,VA',\n",
    " 'Arlington,VA',\n",
    " 'Appleton,WI',\n",
    " 'RockHill,SC',\n",
    " 'Fargo,ND',\n",
    " 'Bremerton,WA',\n",
    " 'GreenBay,WI',\n",
    " 'Enterprise,NV',\n",
    " 'SpringValley,NV',\n",
    " 'Tacoma,WA',\n",
    " 'Roanoke,VA',\n",
    " 'Brownsville,TX',\n",
    " 'CollegeStation,TX',\n",
    " 'Olympia,WA',\n",
    " 'Clarksville,TN',\n",
    " 'Portland,ME',\n",
    " 'Hickory,NC',\n",
    " 'Amarillo,TX',\n",
    " 'Waterbury,CT',\n",
    " 'Frisco,TX',\n",
    " 'Lorain,OH',\n",
    " 'Kalamazoo,MI',\n",
    " 'Galveston,TX',\n",
    " 'Spartanburg,SC',\n",
    " 'SunriseManor,NV',\n",
    " 'GrandPrairie,TX',\n",
    " 'McKinney,TX',\n",
    " 'Waco,TX',\n",
    " 'Nampa,ID',\n",
    " 'CedarRapids,IA',\n",
    " 'Vancouver,WA',\n",
    " 'Paradise,NV',\n",
    " 'NewportNews,VA',\n",
    " 'Murfreesboro,TN',\n",
    " 'Danbury,CT',\n",
    " 'Gastonia,NC',\n",
    " 'Fredericksburg,VA',\n",
    " 'Cary,NC',\n",
    " 'Manchester,NH',\n",
    " 'Medford,OR',\n",
    " 'Mauldin,SC',\n",
    " 'Norwich,CT',\n",
    " 'Muskegon,MI',\n",
    " 'HighPoint,NC',\n",
    " 'Marysville,WA',\n",
    " 'Alexandria,VA',\n",
    " 'Lakewood,CO',\n",
    " 'Odessa,TX',\n",
    " 'NewBedford,MA',\n",
    " 'SouthLyon,MI',\n",
    " 'Pasadena,TX',\n",
    " 'Bellevue,WA',\n",
    " 'Mesquite,TX',\n",
    " 'St.George,UT',\n",
    " 'Burlington,NC',\n",
    " 'Columbia,MO',\n",
    " 'Thornton,CO',\n",
    " 'Greeley,CO',\n",
    " 'Beaumont,TX',\n",
    " 'Midland,TX',\n",
    " 'WestValleyCity,UT',\n",
    " 'Warren,MI',\n",
    " 'GrandJunction,CO',\n",
    " 'Tyler,TX',\n",
    " 'Hampton,VA',\n",
    " 'Stamford,CT',\n",
    " 'Kent,WA',\n",
    " \"Coeurd'Alene,ID\",\n",
    " 'SterlingHeights,MI',\n",
    " 'Yakima,WA',\n",
    " 'Carrollton,TX',\n",
    " 'Racine,WI',\n",
    " 'JohnsonCity,TN',\n",
    " 'Billings,MT',\n",
    " 'IowaCity,IA',\n",
    " 'Dover,DE',\n",
    " 'Bellingham,WA',\n",
    " 'Lynchburg,VA',\n",
    " 'Norman,OK',\n",
    " 'Greenville,NC',\n",
    " 'FortSmith,AR',\n",
    " 'Abilene,TX',\n",
    " 'Lewisville,TX',\n",
    " 'Pearland,TX',\n",
    " 'Kenosha,WI',\n",
    " 'Burlington,VT',\n",
    " 'Arvada,CO',\n",
    " 'Independence,MO',\n",
    " 'Rochester,MN',\n",
    " 'Logan,UT',\n",
    " 'Harlingen,TX',\n",
    " 'RoundRock,TX',\n",
    " 'Pueblo,CO',\n",
    " 'Temple,TX',\n",
    " 'Meridian,ID',\n",
    " 'Duluth,MN',\n",
    " 'TheWoodlands,TX',\n",
    " 'Boulder,CO',\n",
    " 'Richardson,TX',\n",
    " 'Cambridge,MA',\n",
    " 'PortArthur,TX',\n",
    " 'St.Cloud,MN',\n",
    " 'WestJordan,UT',\n",
    " 'NorthCharleston,SC',\n",
    " 'Westminster,CO',\n",
    " 'Saginaw,MI',\n",
    " 'Lowell,MA',\n",
    " 'BrokenArrow,OK',\n",
    " 'Gresham,OR',\n",
    " 'LeagueCity,TX',\n",
    " 'Waterloo,IA',\n",
    " 'Leominster,MA',\n",
    " 'Longview,TX',\n",
    " 'Jacksonville,NC',\n",
    " 'Bend,OR',\n",
    " 'SiouxCity,IA',\n",
    " 'Everett,WA',\n",
    " 'SugarLand,TX',\n",
    " 'EauClaire,WI',\n",
    " 'IdahoFalls,ID',\n",
    " 'Dearborn,MI',\n",
    " 'Sparks,NV',\n",
    " 'Centennial,CO',\n",
    " 'Hillsboro,OR',\n",
    " 'Allen,TX',\n",
    " 'Renton,WA',\n",
    " 'Holland,MI',\n",
    " 'Brockton,MA',\n",
    " 'SpokaneValley,WA',\n",
    " 'Charlottesville,VA',\n",
    " 'WichitaFalls,TX',\n",
    " \"Lee'sSummit,MO\",\n",
    " 'Longmont,CO',\n",
    " 'HighlandsRanch,CO',\n",
    " 'Kingsport,TN',\n",
    " 'Quincy,MA',\n",
    " 'Edinburg,TX',\n",
    " 'Lynn,MA',\n",
    " 'SanAngelo,TX']\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(data_list, columns=['Cities'])\n",
    "df.to_csv('cities_to_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a828507e-a694-4feb-88e8-1ac08dee0c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------Code to use in local terminal to access yelp api files----------------------------\n",
    "#!/bin/bash\n",
    "\n",
    "# Yelp API Key\n",
    "API_KEY=\"yourkey\"\n",
    "\n",
    "# Define cities array\n",
    "cities=(\n",
    "    \"Allen,TX\"\n",
    "    \"AnnArbor,MI\"\n",
    "    \"Enterprise,NV\"\n",
    "    \"Gresham,OR\"\n",
    "    \"Henderson,NV\"\n",
    "    \"NorthLasVegas,NV\"\n",
    "    \"Paradise,NV\"\n",
    "    \"Portland,OR\"\n",
    "    \"Richardson,TX\"\n",
    "    \"SpringValley,NV\"\n",
    "    \"Stamford,CT\"\n",
    "    \"SunriseManor,NV\"\n",
    "    \"Vancouver,WA\"\n",
    "    )\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "# Loop through each city in the array\n",
    "for city in \"${cities[@]}\"; do        \n",
    "        curl --request GET \\\n",
    "             --url \"https://api.yelp.com/v3/businesses/search?term=adult+entertainment&location=$city&sort_by=best_match&limit=50&offset=40\" \\\n",
    "             --header \"Authorization: Bearer $API_KEY\" \\\n",
    "             --header \"accept: application/json\" > \"${city// /}_rest.json\"\n",
    "\n",
    "        echo \"Data for $city with offset $offset saved to ${city// /}_rest.json\"\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2004eb-272c-4224-9d28-85cf0fb7bd15",
   "metadata": {},
   "source": [
    "### Combining files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25bc41f-525f-424a-a55d-bcc8f9ddb84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------combining all .json files into one csv-----------------------------------------\n",
    "#this code combines all of the files that have each address listed\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "#normalize nested json files to get a df of business details\n",
    "def read_json_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        # 'businesses' is the key containing the list of business dictionaries\n",
    "        if 'businesses' in data:\n",
    "            return pd.json_normalize(data['businesses'])\n",
    "        else:\n",
    "            print(f\"No 'businesses' key found in {filepath}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "directory = 'yourdirectory'\n",
    "json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
    "\n",
    "dataframes = []\n",
    "for json_file in json_files:\n",
    "    df = read_json_file(os.path.join(directory, json_file))\n",
    "    if df is not None:\n",
    "        dataframes.append(df)\n",
    "\n",
    "if dataframes:\n",
    "    SOBfirst20 = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Successfully concatenated DataFrames\")\n",
    "else:\n",
    "    print(\"No valid DataFrames to concatenate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac30ece0-71c5-40b7-9425-0800fc17000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify total business counts by city\n",
    "def extract_business_count(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        business_count = data.get('total', 0)  # Assuming 'total' is the key holding count\n",
    "        return business_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "directory = 'yourdirectory'\n",
    "json_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.json')]\n",
    "\n",
    "business_counts = []\n",
    "for json_file in json_files:\n",
    "    count = extract_business_count(json_file)\n",
    "    if count is not None:\n",
    "        city_name = os.path.splitext(os.path.basename(json_file))[0]  # Extract city name from file name\n",
    "        business_counts.append({'City': city_name, 'Business_Count': count})\n",
    "\n",
    "if business_counts:\n",
    "    df = pd.DataFrame(business_counts)\n",
    "    csv_output = 'yourfile'\n",
    "    df.to_csv(csv_output, index=False)\n",
    "    print(f\"Successfully saved business counts to {csv_output}\")\n",
    "else:\n",
    "    print(\"No valid business counts to save\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
