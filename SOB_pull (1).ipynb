{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "128b49b8-5338-4dda-b05c-289695eb58dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#list of cities:\n",
    "#ADD TX cities that we did in initial pull \n",
    "# (Austin, TX, Dallas, TX, Fort Worth, TX, Houston, TX, San Antonio, TX, Laredo, TX)\n",
    "data_list=[\n",
    " 'Washington,DC',\n",
    " 'Boston,MA',\n",
    " 'Detroit,MI',\n",
    " 'Seattle,WA',\n",
    " 'Minneapolis,MN',\n",
    " 'Denver,CO',\n",
    " 'St.Louis,MO',\n",
    " 'Portland,OR',\n",
    " 'Cincinnati,OH',\n",
    " 'KansasCity,MO',\n",
    " 'Cleveland,OH',\n",
    " 'Columbus,OH',\n",
    " 'VirginiaBeach,VA',\n",
    " 'Charlotte,NC',\n",
    " 'Milwaukee,WI',\n",
    " 'Providence,RI',\n",
    " 'Nashville,TN',\n",
    " 'SaltLakeCity,UT',\n",
    " 'Raleigh,NC',\n",
    " 'Richmond,VA',\n",
    " 'Memphis,TN',\n",
    " 'OklahomaCity,OK',\n",
    " 'Hartford,CT',\n",
    " 'Louisville,KY',\n",
    " 'Bridgeport,CT',\n",
    " 'McAllen,TX',\n",
    " 'Tulsa,OK',\n",
    " 'Charleston,SC',\n",
    " 'Dayton,OH',\n",
    " 'ColoradoSprings,CO',\n",
    " 'Ogden,UT',\n",
    " 'Provo,UT',\n",
    " 'Knoxville,TN',\n",
    " 'GrandRapids,MI',\n",
    " 'Columbia,SC',\n",
    " 'NewHaven,CT',\n",
    " 'DesMoines,IA',\n",
    " 'Akron,OH',\n",
    " 'Toledo,OH',\n",
    " 'Worcester,MA',\n",
    " 'LittleRock,AR',\n",
    " 'Reno,NV',\n",
    " 'Spokane,WA',\n",
    " 'Madison,WI',\n",
    " 'Boise,ID',\n",
    " 'Denton,TX',\n",
    " 'Springfield,MA',\n",
    " 'Winston-Salem,NC',\n",
    " 'Chattanooga,TN',\n",
    " 'Greenville,SC',\n",
    " 'Durham,NC',\n",
    " 'Fayetteville,AR',\n",
    " 'Arlington,TX',\n",
    " 'Aurora,CO',\n",
    " 'Greensboro,NC',\n",
    " 'CorpusChristi,TX',\n",
    " 'FortCollins,CO',\n",
    " 'MyrtleBeach,SC',\n",
    " 'Fayetteville,NC',\n",
    " 'Lansing,MI',\n",
    " 'Lexington,KY',\n",
    " 'Youngstown,OH',\n",
    " 'Henderson,NV',\n",
    " 'AnnArbor,MI',\n",
    " 'St.Paul,MN',\n",
    " 'Canton,OH',\n",
    " 'Asheville,NC',\n",
    " 'Flint,MI',\n",
    " 'Concord,NC',\n",
    " 'Springfield,MO',\n",
    " 'Plano,TX',\n",
    " 'Davenport,IA',\n",
    " 'Lubbock,TX',\n",
    " 'Eugene,OR',\n",
    " 'Wilmington,NC',\n",
    " 'Salem,OR',\n",
    " 'Killeen,TX',\n",
    " 'NorthLasVegas,NV',\n",
    " 'Kennewick,WA',\n",
    " 'Irving,TX',\n",
    " 'Chesapeake,VA',\n",
    " 'Nashua,NH',\n",
    " 'Garland,TX',\n",
    " 'Norfolk,VA',\n",
    " 'Arlington,VA',\n",
    " 'Appleton,WI',\n",
    " 'RockHill,SC',\n",
    " 'Fargo,ND',\n",
    " 'Bremerton,WA',\n",
    " 'GreenBay,WI',\n",
    " 'Enterprise,NV',\n",
    " 'SpringValley,NV',\n",
    " 'Tacoma,WA',\n",
    " 'Roanoke,VA',\n",
    " 'Brownsville,TX',\n",
    " 'CollegeStation,TX',\n",
    " 'Olympia,WA',\n",
    " 'Clarksville,TN',\n",
    " 'Portland,ME',\n",
    " 'Hickory,NC',\n",
    " 'Amarillo,TX',\n",
    " 'Waterbury,CT',\n",
    " 'Frisco,TX',\n",
    " 'Lorain,OH',\n",
    " 'Kalamazoo,MI',\n",
    " 'Galveston,TX',\n",
    " 'Spartanburg,SC',\n",
    " 'SunriseManor,NV',\n",
    " 'GrandPrairie,TX',\n",
    " 'McKinney,TX',\n",
    " 'Waco,TX',\n",
    " 'Nampa,ID',\n",
    " 'CedarRapids,IA',\n",
    " 'Vancouver,WA',\n",
    " 'Paradise,NV',\n",
    " 'NewportNews,VA',\n",
    " 'Murfreesboro,TN',\n",
    " 'Danbury,CT',\n",
    " 'Gastonia,NC',\n",
    " 'Fredericksburg,VA',\n",
    " 'Cary,NC',\n",
    " 'Manchester,NH',\n",
    " 'Medford,OR',\n",
    " 'Mauldin,SC',\n",
    " 'Norwich,CT',\n",
    " 'Muskegon,MI',\n",
    " 'HighPoint,NC',\n",
    " 'Marysville,WA',\n",
    " 'Alexandria,VA',\n",
    " 'Lakewood,CO',\n",
    " 'Odessa,TX',\n",
    " 'NewBedford,MA',\n",
    " 'SouthLyon,MI',\n",
    " 'Pasadena,TX',\n",
    " 'Bellevue,WA',\n",
    " 'Mesquite,TX',\n",
    " 'St.George,UT',\n",
    " 'Burlington,NC',\n",
    " 'Columbia,MO',\n",
    " 'Thornton,CO',\n",
    " 'Greeley,CO',\n",
    " 'Beaumont,TX',\n",
    " 'Midland,TX',\n",
    " 'WestValleyCity,UT',\n",
    " 'Warren,MI',\n",
    " 'GrandJunction,CO',\n",
    " 'Tyler,TX',\n",
    " 'Hampton,VA',\n",
    " 'Stamford,CT',\n",
    " 'Kent,WA',\n",
    " \"Coeurd'Alene,ID\",\n",
    " 'SterlingHeights,MI',\n",
    " 'Yakima,WA',\n",
    " 'Carrollton,TX',\n",
    " 'Racine,WI',\n",
    " 'JohnsonCity,TN',\n",
    " 'Billings,MT',\n",
    " 'IowaCity,IA',\n",
    " 'Dover,DE',\n",
    " 'Bellingham,WA',\n",
    " 'Lynchburg,VA',\n",
    " 'Norman,OK',\n",
    " 'Greenville,NC',\n",
    " 'FortSmith,AR',\n",
    " 'Abilene,TX',\n",
    " 'Lewisville,TX',\n",
    " 'Pearland,TX',\n",
    " 'Kenosha,WI',\n",
    " 'Burlington,VT',\n",
    " 'Arvada,CO',\n",
    " 'Independence,MO',\n",
    " 'Rochester,MN',\n",
    " 'Logan,UT',\n",
    " 'Harlingen,TX',\n",
    " 'RoundRock,TX',\n",
    " 'Pueblo,CO',\n",
    " 'Temple,TX',\n",
    " 'Meridian,ID',\n",
    " 'Duluth,MN',\n",
    " 'TheWoodlands,TX',\n",
    " 'Boulder,CO',\n",
    " 'Richardson,TX',\n",
    " 'Cambridge,MA',\n",
    " 'PortArthur,TX',\n",
    " 'St.Cloud,MN',\n",
    " 'WestJordan,UT',\n",
    " 'NorthCharleston,SC',\n",
    " 'Westminster,CO',\n",
    " 'Saginaw,MI',\n",
    " 'Lowell,MA',\n",
    " 'BrokenArrow,OK',\n",
    " 'Gresham,OR',\n",
    " 'LeagueCity,TX',\n",
    " 'Waterloo,IA',\n",
    " 'Leominster,MA',\n",
    " 'Longview,TX',\n",
    " 'Jacksonville,NC',\n",
    " 'Bend,OR',\n",
    " 'SiouxCity,IA',\n",
    " 'Everett,WA',\n",
    " 'SugarLand,TX',\n",
    " 'EauClaire,WI',\n",
    " 'IdahoFalls,ID',\n",
    " 'Dearborn,MI',\n",
    " 'Sparks,NV',\n",
    " 'Centennial,CO',\n",
    " 'Hillsboro,OR',\n",
    " 'Allen,TX',\n",
    " 'Renton,WA',\n",
    " 'Holland,MI',\n",
    " 'Brockton,MA',\n",
    " 'SpokaneValley,WA',\n",
    " 'Charlottesville,VA',\n",
    " 'WichitaFalls,TX',\n",
    " \"Lee'sSummit,MO\",\n",
    " 'Longmont,CO',\n",
    " 'HighlandsRanch,CO',\n",
    " 'Kingsport,TN',\n",
    " 'Quincy,MA',\n",
    " 'Edinburg,TX',\n",
    " 'Lynn,MA',\n",
    " 'SanAngelo,TX']\n",
    "# Convert list to DataFrame\n",
    "df = pd.DataFrame(data_list, columns=['Cities'])\n",
    "df.to_csv('cities_to_counties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8a723-f69f-4ba2-994d-c86ae36a2c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------Code to use in local terminal to access yelp api files----------------------------\n",
    "#!/bin/bash\n",
    "\n",
    "# Yelp API Key\n",
    "API_KEY=\"H9woqbScRgVxlC55FTn6xE7mlRUBmr0K7LuuQVNYiuzQd5_sFiNrb_cfYPjF-jmYvW5VAjq7jccZ6IKsSzZtZkL3u18zcSQz1QPXC0mS6G5exBHMfIpmDbqD7At_ZnYx\"\n",
    "\n",
    "# Define cities array\n",
    "cities=(\n",
    "    \"Allen,TX\"\n",
    "    \"AnnArbor,MI\"\n",
    "    \"Enterprise,NV\"\n",
    "    \"Gresham,OR\"\n",
    "    \"Henderson,NV\"\n",
    "    \"NorthLasVegas,NV\"\n",
    "    \"Paradise,NV\"\n",
    "    \"Portland,OR\"\n",
    "    \"Richardson,TX\"\n",
    "    \"SpringValley,NV\"\n",
    "    \"Stamford,CT\"\n",
    "    \"SunriseManor,NV\"\n",
    "    \"Vancouver,WA\"\n",
    "    )\n",
    "\n",
    "\n",
    ")\n",
    "\n",
    "# Loop through each city in the array\n",
    "for city in \"${cities[@]}\"; do        \n",
    "        curl --request GET \\\n",
    "             --url \"https://api.yelp.com/v3/businesses/search?term=adult+entertainment&location=$city&sort_by=best_match&limit=50&offset=40\" \\\n",
    "             --header \"Authorization: Bearer $API_KEY\" \\\n",
    "             --header \"accept: application/json\" > \"${city// /}_rest.json\"\n",
    "\n",
    "        echo \"Data for $city with offset $offset saved to ${city// /}_rest.json\"\n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0915698c-c308-4362-a393-a2a536d5c5b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/users/eyenawine/NIBRS_2/SOB_pull/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     21\u001b[0m directory \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/users/eyenawine/NIBRS_2/SOB_pull/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 22\u001b[0m json_files \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m f\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     24\u001b[0m dataframes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m json_file \u001b[38;5;129;01min\u001b[39;00m json_files:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/users/eyenawine/NIBRS_2/SOB_pull/'"
     ]
    }
   ],
   "source": [
    "#---------------------------combining all .json files into one csv-----------------------------------------\n",
    "#this code combines all of the files that have each address by \n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "#normalize nested json files to get a df of business details\n",
    "def read_json_file(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        # 'businesses' is the key containing the list of business dictionaries\n",
    "        if 'businesses' in data:\n",
    "            return pd.json_normalize(data['businesses'])\n",
    "        else:\n",
    "            print(f\"No 'businesses' key found in {filepath}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "directory = '/users/eyenawine/NIBRS_2/SOB_pull/'\n",
    "json_files = [f for f in os.listdir(directory) if f.endswith('.json')]\n",
    "\n",
    "dataframes = []\n",
    "for json_file in json_files:\n",
    "    df = read_json_file(os.path.join(directory, json_file))\n",
    "    if df is not None:\n",
    "        dataframes.append(df)\n",
    "\n",
    "if dataframes:\n",
    "    SOBfirst20 = pd.concat(dataframes, ignore_index=True)\n",
    "    print(\"Successfully concatenated DataFrames\")\n",
    "else:\n",
    "    print(\"No valid DataFrames to concatenate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e457ceca-1622-40f1-aeb8-86720506af31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataframe to csv\n",
    "SOBfirst20.to_csv('SOBlist2.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e7781b6-990b-4155-bd02-19280ed54694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved business counts to /users/eyenawine/NIBRS_2/SOB_pull/business_counts.csv\n"
     ]
    }
   ],
   "source": [
    "#identify total business counts by city\n",
    "def extract_business_count(filepath):\n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "        \n",
    "        business_count = data.get('total', 0)  # Assuming 'total' is the key holding count\n",
    "        return business_count\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {filepath}: {e}\")\n",
    "        return None\n",
    "\n",
    "directory = '/users/eyenawine/NIBRS_2/SOB_pull/'\n",
    "json_files = [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.json')]\n",
    "\n",
    "business_counts = []\n",
    "for json_file in json_files:\n",
    "    count = extract_business_count(json_file)\n",
    "    if count is not None:\n",
    "        city_name = os.path.splitext(os.path.basename(json_file))[0]  # Extract city name from file name\n",
    "        business_counts.append({'City': city_name, 'Business_Count': count})\n",
    "\n",
    "if business_counts:\n",
    "    df = pd.DataFrame(business_counts)\n",
    "    csv_output = '/users/eyenawine/NIBRS_2/SOB_pull/business_counts.csv'\n",
    "    df.to_csv(csv_output, index=False)\n",
    "    print(f\"Successfully saved business counts to {csv_output}\")\n",
    "else:\n",
    "    print(\"No valid business counts to save\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a3bc9-c29a-4e39-91c4-318a2989db69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unable to collect beyond 50 for each search result:\n",
    "# Nevada, primarily duplicates\n",
    "# the rest are only missing one to two locations, willing to overlook this lack of data\n",
    "# Enterprise,NV_0\t80\n",
    "# 10\tNorthLasVegas,NV_0\t84\n",
    "# 12\tParadise,NV_0\t84\n",
    "# 18\tSpringValley,NV_0\t82\n",
    "# 22\tSunriseManor,NV_0\t82\n",
    "# 24\tVancouver,WA_0\t51\n",
    "# 14\tPortland,OR_0\t51\n",
    "# 6\tGresham,OR_40\t52"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
