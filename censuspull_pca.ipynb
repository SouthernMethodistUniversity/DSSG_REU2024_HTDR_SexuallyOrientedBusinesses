{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d40ea23e-c1c7-4ec5-98c1-e34ad22d3e8c",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ecc9b2-c0a2-4b51-bd45-496ac5f43e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cenpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b512c-232f-4ed3-8c75-83302ca14d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip show cenpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68819c20-47ee-4890-9a65-a823c1fcf074",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173bf88e-4a1e-46f1-af92-f599cf34087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1655c43-34bb-4105-bbd4-b536eb8b284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------Import modules----------------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from census import Census\n",
    "from us import states\n",
    "import os\n",
    "import requests\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed611b8-82d6-47aa-93c2-c12613a5b457",
   "metadata": {},
   "source": [
    "### Census Data Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f8d3c8-95be-45a4-8c7c-a08a0d80611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#--------------------------------------------------Set API key------------------------------------------------------------------------------------\n",
    "c = Census(\"yourkey\")\n",
    "#---------------------------------Selection of Data from American Community Survey 2022 5-Year-----------------------------------------------------------\n",
    "fields = (\n",
    "    'NAME', # County_State\n",
    "    'B01003_001E', \n",
    "    'B01001_002E', \n",
    "    'B01001_003E', \n",
    "    'B01001_004E', \n",
    "    'B01001_005E',\n",
    "    'B01001_006E', \n",
    "    'B01001_007E', \n",
    "    'B01001_008E', \n",
    "    'B01001_009E', \n",
    "    'B01001_010E',\n",
    "    'B01001_011E', \n",
    "    'B01001_012E', \n",
    "    'B01001_013E', \n",
    "    'B01001_014E', \n",
    "    'B01001_015E',\n",
    "    'B01001_016E', \n",
    "    'B01001_017E', \n",
    "    'B01001_018E', \n",
    "    'B01001_019E', \n",
    "    'B01001_020E',\n",
    "    'B01001_021E', \n",
    "    'B01001_022E', \n",
    "    'B01001_023E', \n",
    "    'B01001_024E', \n",
    "    'B02001_002E',\n",
    "    'B02001_003E', \n",
    "    'B02001_004E',\n",
    "    'B02001_005E', \n",
    "    'B02001_006E', \n",
    "    'B02001_007E',\n",
    "    'B02001_008E', \n",
    "    'B03001_002E', \n",
    "    'B03001_003E', \n",
    "    'B11001_001E', \n",
    "    'B19013_001E',\n",
    "    'B17001_002E', \n",
    "    'B23025_001E', \n",
    "    'B23025_004E', \n",
    "    'B23025_005E', \n",
    "    'B15003_022E',\n",
    "    'B25077_001E', \n",
    "    'B25064_001E', \n",
    "    'B25003_002E', \n",
    "    'C24010_001E', \n",
    "    'C24010_002E',\n",
    "    'C24010_003E', \n",
    "    'C24010_004E', \n",
    "    'C24010_005E', \n",
    "    'C24010_006E', \n",
    "    'C24010_007E',\n",
    "    'C24010_008E', \n",
    "    'C24010_009E', \n",
    "    'C24010_010E', \n",
    "    'C24010_011E', \n",
    "    'C24010_012E',\n",
    "    'C24010_013E', \n",
    "    'C24010_014E', \n",
    "    'B27001_002E', \n",
    "    'B27001_003E'  \n",
    ")\n",
    "#state_county(fields, state_fips, county_fips)\n",
    "us_df = pd.DataFrame()\n",
    "for state in states.STATES:\n",
    "    state_fips = state.fips\n",
    "    print(f\"Collecting the data for : {state.name} (FIPS: {state_fips})\")\n",
    "    state_data = c.acs5.state_county(fields=fields, state_fips=state_fips, county_fips=\"*\", year=2022)\n",
    "    state_df = pd.DataFrame(state_data)\n",
    "    us_df = pd.concat([us_df, state_df], ignore_index=True)\n",
    "    #-----------------------------------------------Rename the Relevant Columns---------------------------------------------------------------------\n",
    "us_df.rename(columns={\n",
    "    'NAME'       : 'County_State',\n",
    "    'name_and_fips': 'name_and_fips',\n",
    "    'B01003_001E': 'Total Population',\n",
    "    'B01001_002E': 'Male Under 5 Years',\n",
    "    'B01001_003E': 'Male 5 to 9 Years',\n",
    "    'B01001_004E': 'Male 10 to 14 Years',\n",
    "    'B01001_005E': 'Male 15 to 17 Years',\n",
    "    'B01001_006E': 'Male 18 and 19 Years',\n",
    "    'B01001_007E': 'Male 20 Years',\n",
    "    'B01001_008E': 'Male 21 Years',\n",
    "    'B01001_009E': 'Male 22 to 24 Years',\n",
    "    'B01001_010E': 'Male 25 to 29 Years',\n",
    "    'B01001_011E': 'Male 30 to 34 Years',\n",
    "    'B01001_012E': 'Male 35 to 39 Years',\n",
    "    'B01001_013E': 'Male 40 to 44 Years',\n",
    "    'B01001_014E': 'Male 45 to 49 Years',\n",
    "    'B01001_015E': 'Male 50 to 54 Years',\n",
    "    'B01001_016E': 'Male 55 to 59 Years',\n",
    "    'B01001_017E': 'Male 60 and 61 Years',\n",
    "    'B01001_018E': 'Male 62 to 64 Years',\n",
    "    'B01001_019E': 'Male 65 and 66 Years',\n",
    "    'B01001_020E': 'Male 67 to 69 Years',\n",
    "    'B01001_021E': 'Male 70 to 74 Years',\n",
    "    'B01001_022E': 'Male 75 to 79 Years',\n",
    "    'B01001_023E': 'Male 80 to 84 Years',\n",
    "    'B01001_024E': 'Male 85 Years and Over',\n",
    "    'B02001_002E': 'White Alone',\n",
    "    'B02001_003E': 'Black or African American Alone',\n",
    "    'B02001_004E': 'American Indian and Alaska Native Alone',\n",
    "    'B02001_005E': 'Asian Alone',\n",
    "    'B02001_006E': 'Native Hawaiian and Other Pacific Islander Alone',\n",
    "    'B02001_007E': 'Some Other Race Alone',\n",
    "    'B02001_008E': 'Two or More Races',\n",
    "    'B03001_002E': 'Hispanic or Latino',\n",
    "    'B03001_003E': 'Not Hispanic or Latino',\n",
    "    'B11001_001E': 'Total Households',\n",
    "    'B19013_001E': 'Median Household Income',\n",
    "    'B17001_002E': 'Below Poverty Level',\n",
    "    'B23025_001E': 'Population 16 Years and Over',\n",
    "    'B23025_004E': 'Employed',\n",
    "    'B23025_005E': 'Unemployed',\n",
    "    'B15003_022E': 'Bachelor\\'s Degree',\n",
    "    'B25077_001E': 'Median Housing Value',\n",
    "    'B25064_001E': 'Median Gross Rent',\n",
    "    'B25003_002E': 'Owner Occupied',\n",
    "    'C24010_001E': 'Total Population for Employment Status',\n",
    "    'C24010_002E': 'Management, Business, Science, and Arts Occupations',\n",
    "    'C24010_003E': 'Service Occupations',\n",
    "    'C24010_004E': 'Sales and Office Occupations',\n",
    "    'C24010_005E': 'Natural Resources, Construction, and Maintenance Occupations',\n",
    "    'C24010_006E': 'Production, Transportation, and Material Moving Occupations',\n",
    "    'C24010_007E': 'Military Specific Occupations',\n",
    "    'C24010_008E': 'Unemployed but in Labor Force',\n",
    "    'C24010_009E': 'Employed but not in Labor Force',\n",
    "    'C24010_010E': 'Not in Labor Force',\n",
    "    'C24010_011E': 'Armed Forces',\n",
    "    'C24010_012E': 'Employed in Armed Forces',\n",
    "    'C24010_013E': 'Unemployed in Armed Forces',\n",
    "    'C24010_014E': 'Not in Armed Forces',\n",
    "    'B27001_002E': 'With Health Insurance Coverage',\n",
    "    'B27001_003E': 'Without Health Insurance Coverage'\n",
    "                       }, inplace=True)\n",
    " #--------------------------------------------------Create GEOID Column------------------------------------------------------------------------\n",
    "us_df['GEOID'] = us_df['state'].astype(str) + us_df['county'].astype(str)\n",
    "#--------------------------------------------------Display the DataFrame------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94e6f71-c61b-44c9-8f41-7ee8e5f91e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "nibrs= pd.read_csv('yourfile.csv')\n",
    "nibrs=nibrs.drop_duplicates('name_and_fips')\n",
    "nibrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154ce636-5125-4c09-bece-69fff14010bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nibrs['GEOID'] = nibrs['GEOID'].astype(str)\n",
    "us_df['GEOID'] = us_df['GEOID'].astype(str)\n",
    "censusdata = pd.merge(nibrs, us_df, on='GEOID', how='left')\n",
    "censusdata.to_csv('yourfile.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00dee106-8260-4ab8-8a42-2e18d385cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Population Density: B01001_001E (total population) divided by B01003_001E (land area in square miles)\n",
    "#this doesn't work because there is not geographic population data\n",
    "censusdata['Population Density'] = censusdata['Total Population']/censusdata['ALAND'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b792950-1dbf-40be-8f8a-e2ac47b57fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the unemployment rate from unemployed divided by labor force\n",
    "censusdata['Unemployment Rate'] = censusdata['Unemployed']/censusdata['Population 16 Years and Over'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70801600-8ae9-4a4b-9072-b7e5cebbe598",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating rates of select variables to reduce colinearity in PCA\n",
    "censusdata['White Alone Rate'] = censusdata['White Alone'] / censusdata['Total Population'] * 100\n",
    "censusdata['Black or African American Alone Rate'] = censusdata['Black or African American Alone'] / censusdata['Total Population'] * 100\n",
    "censusdata['American Indian and Alaska Native Alone Rate'] = censusdata['American Indian and Alaska Native Alone'] / censusdata['Total Population'] * 100\n",
    "censusdata['Asian Alone Rate'] = censusdata['Asian Alone'] / censusdata['Total Population'] * 100\n",
    "censusdata['Native Hawaiian and Other Pacific Islander Alone Rate'] = censusdata['Native Hawaiian and Other Pacific Islander Alone'] / censusdata['Total Population'] * 100\n",
    "censusdata['Some Other Race Alone Rate'] = censusdata['Some Other Race Alone'] / censusdata['Total Population'] * 100\n",
    "censusdata['Two or More Races Rate'] = censusdata['Two or More Races'] / censusdata['Total Population'] * 100\n",
    "censusdata['Hispanic or Latino Rate'] = censusdata['Hispanic or Latino'] / censusdata['Total Population'] * 100\n",
    "censusdata['Below Poverty Level Rate'] = censusdata['Below Poverty Level'] / censusdata['Total Population'] * 100\n",
    "censusdata['Bachelor\\'s Degree Rate'] = censusdata['Bachelor\\'s Degree'] / censusdata['Total Population'] * 100\n",
    "censusdata['Management, Business, Science, and Arts Occupations Rate'] = censusdata['Management, Business, Science, and Arts Occupations'] / censusdata['Total Population'] * 100\n",
    "censusdata['Service Occupations Rate'] = censusdata['Service Occupations'] / censusdata['Total Population'] * 100\n",
    "censusdata['Sales and Office Occupations Rate'] = censusdata['Sales and Office Occupations'] / censusdata['Total Population'] * 100\n",
    "censusdata['Natural Resources, Construction, and Maintenance Occupations Rate'] = censusdata['Natural Resources, Construction, and Maintenance Occupations'] / censusdata['Total Population'] * 100\n",
    "censusdata['Production, Transportation, and Material Moving Occupations Rate'] = censusdata['Production, Transportation, and Material Moving Occupations'] / censusdata['Total Population'] * 100\n",
    "censusdata['Military Specific Occupations Rate'] = censusdata['Military Specific Occupations'] / censusdata['Total Population'] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aed695-eadf-4c40-85df-d52ce6ff6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = censusdata[\n",
    "    [\n",
    "        'County_State',\n",
    "        'White Alone Rate',\n",
    "        'Black or African American Alone Rate',\n",
    "        'American Indian and Alaska Native Alone Rate',\n",
    "        'Asian Alone Rate',\n",
    "        'Native Hawaiian and Other Pacific Islander Alone Rate',\n",
    "        'Some Other Race Alone Rate',\n",
    "        'Two or More Races Rate',\n",
    "        'Hispanic or Latino Rate',\n",
    "        'Below Poverty Level Rate',\n",
    "        'Bachelor\\'s Degree Rate',\n",
    "        'Management, Business, Science, and Arts Occupations Rate',\n",
    "        'Service Occupations Rate',\n",
    "        'Sales and Office Occupations Rate',\n",
    "        'Natural Resources, Construction, and Maintenance Occupations Rate',\n",
    "        'Production, Transportation, and Material Moving Occupations Rate',\n",
    "        'Military Specific Occupations Rate',\n",
    "        'Total Population',\n",
    "        'Population Density',\n",
    "        'Median Household Income',\n",
    "        'Median Gross Rent',\n",
    "        'Unemployment Rate'\n",
    "    ]\n",
    "]\n",
    "pca_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dba638-5a93-48bd-b178-9e1c6b8ab34e",
   "metadata": {},
   "source": [
    "### Conduct PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b1096-6d5a-42df-8a80-7c5c5d34cb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove Highly Correlated Variables: using correlation matrix\n",
    "#Identify and remove one of the variables in pairs of highly correlated features (correlation coefficient close to 1 or -1).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming pca_df is your DataFrame and 'NAME' and 'name_and_fips' are columns to exclude\n",
    "columns_to_exclude = ['County_State']\n",
    "\n",
    "# Filter out columns to exclude\n",
    "columns_to_use = [col for col in pca_df.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Subset the DataFrame with columns to use\n",
    "pca_df_subset = pca_df[columns_to_use]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(pca_df_subset)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "corr_matrix = pd.DataFrame(standardized_data, columns=columns_to_use).corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.9\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.9)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "pca_df_final = pd.DataFrame(standardized_data, columns=columns_to_use).drop(columns=to_drop)\n",
    "\n",
    "# Print the final columns after dropping highly correlated features\n",
    "\n",
    "pca_df_final = pd.concat([pca_df_final, pca_df[columns_to_exclude]], axis=1)\n",
    "pca_df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc6efd-0d5a-4e27-99ac-bfafd97b46fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# Assuming pca_df_final is your DataFrame and 'County_State' is the column to exclude\n",
    "columns_to_exclude = ['County_State']\n",
    "\n",
    "# Filter out columns to exclude\n",
    "columns_to_use = [col for col in pca_df_final.columns if col not in columns_to_exclude]\n",
    "\n",
    "# Subset the DataFrame with columns to use\n",
    "pca_df_subset = pca_df_final[columns_to_use]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "standardized_data = scaler.fit_transform(pca_df_subset)\n",
    "\n",
    "# Create a DataFrame from the standardized data\n",
    "standardized_df = pd.DataFrame(standardized_data, columns=columns_to_use)\n",
    "\n",
    "# Handle missing or infinite values\n",
    "standardized_df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "standardized_df.dropna(inplace=True)\n",
    "\n",
    "# Recalculate standardized data after dropping missing values\n",
    "standardized_data_clean = standardized_df.values\n",
    "\n",
    "# Calculate VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"feature\"] = standardized_df.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(standardized_data_clean, i) for i in range(standardized_data_clean.shape[1])]\n",
    "\n",
    "# Drop features with VIF > 10\n",
    "features_to_keep = vif_data[vif_data['VIF'] <= 10]['feature']\n",
    "pca_df_final1 = standardized_df[features_to_keep]\n",
    "\n",
    "# Optionally, add back the excluded columns for reference\n",
    "pca_df_final1 = pd.concat([pca_df_final1.reset_index(drop=True), pca_df_final[columns_to_exclude].reset_index(drop=True)], axis=1)\n",
    "\n",
    "###########\n",
    "\n",
    "# Ensure no NaN values are present\n",
    "pca_df_final1.dropna(inplace=True)\n",
    "\n",
    "# Initialize K-means with the desired number of clusters\n",
    "n_clusters = 3  # Example: choose the number of clusters\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "\n",
    "# Fit K-means to the transformed data\n",
    "kmeans.fit(pca_df_final1[features_to_keep])\n",
    "\n",
    "# Obtain cluster labels\n",
    "cluster_labels = kmeans.labels_\n",
    "\n",
    "# Add cluster labels to the DataFrame\n",
    "pca_df_final1['Cluster'] = cluster_labels\n",
    "\n",
    "# Print the cluster centers (if needed)\n",
    "print(\"Cluster centers:\\n\", kmeans.cluster_centers_)\n",
    "\n",
    "# Print the DataFrame with clusters\n",
    "print(pca_df_final1.head())\n",
    "############################Visualizations###############################\n",
    "# Create a DataFrame for the PCA components\n",
    "# 1. Scatter Plot with PCA\n",
    "pca = PCA(n_components=2)\n",
    "pca_components = pca.fit_transform(pca_df_final1[features_to_keep])\n",
    "pca_components_df = pd.DataFrame(pca_components, columns=['PC1', 'PC2'])\n",
    "pca_components_df['Cluster'] = pca_df_final1['Cluster']\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "for cluster in range(n_clusters):\n",
    "    cluster_data = pca_components_df[pca_components_df['Cluster'] == cluster]\n",
    "    plt.scatter(cluster_data['PC1'], cluster_data['PC2'], label=f'Cluster {cluster}', alpha=0.6)\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.title('KMeans Clustering Visualization with PCA')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
